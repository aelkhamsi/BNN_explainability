{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST data\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.1337,], [0.3086,])]) #?\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0     6     3     2\n"
     ]
    }
   ],
   "source": [
    "# Data visualization\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct the neural network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss function & optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achraf/anaconda3/envs/AI/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.560\n",
      "[1,  4000] loss: 0.430\n",
      "[1,  6000] loss: 0.357\n",
      "[1,  8000] loss: 0.342\n",
      "[1, 10000] loss: 0.303\n",
      "[1, 12000] loss: 0.285\n",
      "[1, 14000] loss: 0.268\n",
      "epoch 1\n",
      "[2,  2000] loss: 0.254\n",
      "[2,  4000] loss: 0.239\n",
      "[2,  6000] loss: 0.228\n",
      "[2,  8000] loss: 0.230\n",
      "[2, 10000] loss: 0.225\n",
      "[2, 12000] loss: 0.242\n",
      "[2, 14000] loss: 0.237\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "## train the model\n",
    "\n",
    "def train():\n",
    "    for epoch in range(2):\n",
    "        print(f\"epoch {epoch}\")\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            images, labels = data\n",
    "            #Forward Pass\n",
    "            outputs = net(images)\n",
    "            #Calculating loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            #Backward pass & update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    print(\"Finished training\")\n",
    "\n",
    "train()\n",
    "\n",
    "#save the model\n",
    "PATH='mnist.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
